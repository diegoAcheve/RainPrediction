{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8f71dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, mean_absolute_error\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense, Dropout\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adam\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cda7f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset types: <bound method NDFrame.describe of            fecha  radiacion  precipitacion_total  viento_promedio  rocio_max  \\\n",
      "0     13/12/2017      19.39                  0.0              6.0        1.7   \n",
      "1     14/12/2017      19.56                  0.0              6.4        1.2   \n",
      "2     15/12/2017      19.26                  0.0              9.3        6.2   \n",
      "3     16/12/2017      17.90                  0.0             15.8        7.7   \n",
      "4     17/12/2017      14.30                  0.2              6.3        7.9   \n",
      "...          ...        ...                  ...              ...        ...   \n",
      "2857  09/10/2025      14.34                  7.5              3.8       14.9   \n",
      "2858  10/10/2025      18.61                 21.9              4.7       14.4   \n",
      "2859  11/10/2025      20.22                  9.6              4.8       13.3   \n",
      "2860  12/10/2025      20.82                  0.2              4.9       13.4   \n",
      "2861  13/10/2025      23.42                  0.7              5.6       12.4   \n",
      "\n",
      "      rocio_min  temp_max  temp_min  presion_max  presion_min  \n",
      "0          -4.0      22.6       0.8        788.2        782.3  \n",
      "1          -2.3      23.8       8.5        787.5        781.3  \n",
      "2          -4.0      24.2       5.6        786.9        779.0  \n",
      "3           2.6      21.4       7.3        787.9        781.1  \n",
      "4           3.4      21.9       8.1        789.4        782.2  \n",
      "...         ...       ...       ...          ...          ...  \n",
      "2857       12.1      20.3      12.7        787.3        782.8  \n",
      "2858       12.6      21.3      13.1        789.8        785.6  \n",
      "2859       10.8      21.5      12.5        788.6        784.6  \n",
      "2860        6.2      23.2      13.6        786.5        783.0  \n",
      "2861        9.3      23.7      10.4        787.2        781.4  \n",
      "\n",
      "[2862 rows x 10 columns]>\n",
      "\n",
      "Dataset shape: (2862, 10)\n",
      "\n",
      "First few rows:\n",
      "        fecha  radiacion  precipitacion_total  viento_promedio  rocio_max  \\\n",
      "0  13/12/2017      19.39                  0.0              6.0        1.7   \n",
      "1  14/12/2017      19.56                  0.0              6.4        1.2   \n",
      "2  15/12/2017      19.26                  0.0              9.3        6.2   \n",
      "3  16/12/2017      17.90                  0.0             15.8        7.7   \n",
      "4  17/12/2017      14.30                  0.2              6.3        7.9   \n",
      "\n",
      "   rocio_min  temp_max  temp_min  presion_max  presion_min  \n",
      "0       -4.0      22.6       0.8        788.2        782.3  \n",
      "1       -2.3      23.8       8.5        787.5        781.3  \n",
      "2       -4.0      24.2       5.6        786.9        779.0  \n",
      "3        2.6      21.4       7.3        787.9        781.1  \n",
      "4        3.4      21.9       8.1        789.4        782.2  \n",
      "\n",
      "Missing values:\n",
      "radiacion              0\n",
      "precipitacion_total    0\n",
      "viento_promedio        0\n",
      "rocio_max              0\n",
      "rocio_min              0\n",
      "temp_max               0\n",
      "temp_min               0\n",
      "presion_max            0\n",
      "presion_min            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# 1. Data Preprocessing\n",
    "print(\"Dataset types:\", df.describe)\n",
    "print(\"\\nDataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Convert date to datetime and set as index\n",
    "df['fecha'] = pd.to_datetime(df['fecha'], dayfirst=True)\n",
    "df = df.set_index('fecha')\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b8f3d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection (excluding target)\n",
    "features = ['temp_max', 'temp_min', 'presion_max', 'presion_min', \n",
    "        'rocio_max', 'rocio_min', 'viento_promedio', 'radiacion']\n",
    "target = 'precipitacion_total'\n",
    "\n",
    "# 2. Data Scaling\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Scale features\n",
    "X_scaled = scaler_x.fit_transform(df[features])\n",
    "# Scale target\n",
    "y_scaled = scaler_y.fit_transform(df[[target]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f601a114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequences shape: X=(2832, 30, 8), y=(2832, 1)\n"
     ]
    }
   ],
   "source": [
    "# 3. Create sequences for LSTM\n",
    "def create_sequences(X, y, time_steps=30):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(time_steps, len(X)):\n",
    "        X_seq.append(X[i-time_steps:i])\n",
    "        y_seq.append(y[i])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Define time steps (using 30 days of historical data)\n",
    "TIME_STEPS = 30\n",
    "X_sequences, y_sequences = create_sequences(X_scaled, y_scaled, TIME_STEPS)\n",
    "\n",
    "print(f\"\\nSequences shape: X={X_sequences.shape}, y={y_sequences.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2006e522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (2265, 30, 8), (2265, 1)\n",
      "Test set: (567, 30, 8), (567, 1)\n"
     ]
    }
   ],
   "source": [
    "# 4. Train-Test Split (chronological split)\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(X_sequences) * split_ratio)\n",
    "\n",
    "X_train = X_sequences[:split_index]\n",
    "X_test = X_sequences[split_index:]\n",
    "y_train = y_sequences[:split_index]\n",
    "y_test = y_sequences[split_index:]\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32740ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Build LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(TIME_STEPS, len(features))),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50),\n",
    "    Dropout(0.2),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='mse', \n",
    "              metrics=['mae'])\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db22eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Train the Model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1,\n",
    "    shuffle=False  # Important for time series data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c538d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Evaluate the Model\n",
    "train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"\\nTraining Loss: {train_loss[0]:.4f}, MAE: {train_loss[1]:.4f}\")\n",
    "print(f\"Test Loss: {test_loss[0]:.4f}, MAE: {test_loss[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1705b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Make Predictions\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_actual = scaler_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b33a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_actual, y_pred)\n",
    "mae = mean_absolute_error(y_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef086b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Plot Results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot training history\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot predictions vs actual\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(y_actual, label='Actual Precipitation', alpha=0.7)\n",
    "plt.plot(y_pred, label='Predicted Precipitation', alpha=0.7)\n",
    "plt.title('Actual vs Predicted Precipitation')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Precipitation')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031b9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Feature Importance Analysis (Optional)\n",
    "# Get the last layer weights to understand feature importance\n",
    "print(\"\\nFeature names:\", features)\n",
    "\n",
    "# 11. Save the Model\n",
    "model.save('rainfall_prediction_lstm.h5')\n",
    "print(\"\\nModel saved as 'rainfall_prediction_lstm.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a524236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make future predictions\n",
    "def predict_future(model, last_sequence, days=7):\n",
    "    \"\"\"\n",
    "    Predict future precipitation for specified number of days\n",
    "    \"\"\"\n",
    "    future_predictions = []\n",
    "    current_sequence = last_sequence.copy()\n",
    "    \n",
    "    for _ in range(days):\n",
    "        # Predict next day\n",
    "        next_pred = model.predict(current_sequence.reshape(1, TIME_STEPS, len(features)))\n",
    "        future_predictions.append(next_pred[0, 0])\n",
    "        \n",
    "        # Update sequence (remove first, add prediction)\n",
    "        current_sequence = np.roll(current_sequence, -1, axis=0)\n",
    "        # For the new row, we need to create a dummy row with the prediction\n",
    "        # In practice, you'd need actual feature values for future dates\n",
    "        new_row = np.zeros(len(features))\n",
    "        # This is simplified - you'd need a better approach for real future predictions\n",
    "        current_sequence[-1] = new_row\n",
    "    \n",
    "    future_predictions = scaler_y.inverse_transform(\n",
    "        np.array(future_predictions).reshape(-1, 1)\n",
    "    )\n",
    "    return future_predictions\n",
    "\n",
    "# Example of future prediction (using the last sequence from test set)\n",
    "if len(X_test) > 0:\n",
    "    last_sequence = X_test[-1]\n",
    "    future_pred = predict_future(model, last_sequence, days=7)\n",
    "    print(f\"\\nNext 7 days precipitation predictions:\")\n",
    "    for i, pred in enumerate(future_pred, 1):\n",
    "        print(f\"Day {i}: {pred[0]:.2f} mm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SistemasExpertos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
