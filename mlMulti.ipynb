{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6100e431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv('data.csv', parse_dates=['fecha'], dayfirst=True)\n",
    "\n",
    "# Ingenier√≠a de caracter√≠sticas temporales\n",
    "df['dia_del_a√±o'] = df['fecha'].dt.dayofyear\n",
    "df['sin_dia'] = np.sin(2 * np.pi * df['dia_del_a√±o'] / 365.25)\n",
    "df['cos_dia'] = np.cos(2 * np.pi * df['dia_del_a√±o'] / 365.25)\n",
    "\n",
    "# Transformar a problema de clasificaci√≥n multiclase\n",
    "def clasificar_precipitacion(precip):\n",
    "    if precip == 0:\n",
    "        return 0  # Nula\n",
    "    elif precip <= 2:\n",
    "        return 1  # Leve\n",
    "    elif precip <= 15:\n",
    "        return 2  # Moderada\n",
    "    else:\n",
    "        return 3  # Intensa\n",
    "\n",
    "df['clase_precipitacion'] = df['precipitacion_total'].apply(clasificar_precipitacion)\n",
    "\n",
    "# Preparar caracter√≠sticas\n",
    "features = ['temp_max', 'temp_min', 'presion_max', 'presion_min', \n",
    "            'rocio_max', 'rocio_min', 'viento_promedio', 'radiacion', \n",
    "            'sin_dia', 'cos_dia']\n",
    "X = df[features]\n",
    "y = df['clase_precipitacion']\n",
    "\n",
    "# Escalado y divisi√≥n\n",
    "scaler = StandardScaler()\n",
    "X_escalado = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_escalado, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definir modelos\n",
    "modelos = {\n",
    "    'SVM': SVC(kernel='rbf', C=1.0, probability=True, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric='mlogloss'),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar modelos\n",
    "resultados = {}\n",
    "for nombre, modelo in modelos.items():\n",
    "    # Entrenamiento\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    y_pred_proba = modelo.predict_proba(X_test) if hasattr(modelo, \"predict_proba\") else None\n",
    "    \n",
    "    # Almacenar resultados\n",
    "    resultados[nombre] = {\n",
    "        'modelo': modelo,\n",
    "        'predicciones': y_pred,\n",
    "        'probabilidades': y_pred_proba\n",
    "    }\n",
    "    print(f\"{nombre} entrenado correctamente\")\n",
    "\n",
    "# Los resultados est√°n disponibles en el diccionario 'resultados'\n",
    "\n",
    "# Comparaci√≥n final de modelos\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARACI√ìN FINAL DE MODELOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear DataFrame para comparaci√≥n\n",
    "comparacion = []\n",
    "for nombre, metrics in resultados.items():\n",
    "    comparacion.append({\n",
    "        'Modelo': nombre,\n",
    "        'Accuracy': f\"{metrics['accuracy']:.4f}\",\n",
    "        'Precision': f\"{metrics['precision']:.4f}\",\n",
    "        'Recall': f\"{metrics['recall']:.4f}\",\n",
    "        'F1-Score': f\"{metrics['f1']:.4f}\",\n",
    "        'Mejores Par√°metros': str(metrics['mejores_parametros'])[:50] + \"...\" if len(str(metrics['mejores_parametros'])) > 50 else metrics['mejores_parametros']\n",
    "    })\n",
    "\n",
    "df_comparacion = pd.DataFrame(comparacion)\n",
    "print(df_comparacion.to_string(index=False))\n",
    "\n",
    "# Mejor modelo basado en F1-Score (balance entre precision y recall)\n",
    "mejor_modelo_nombre = max(resultados.items(), key=lambda x: x[1]['f1'])[0]\n",
    "mejor_modelo = resultados[mejor_modelo_nombre]['modelo']\n",
    "\n",
    "print(f\"\\n MEJOR MODELO: {mejor_modelo_nombre} (F1-Score: {resultados[mejor_modelo_nombre]['f1']:.4f})\")\n",
    "\n",
    "# Reporte de clasificaci√≥n detallado del mejor modelo\n",
    "print(f\"\\nREPORTE DE CLASIFICACI√ìN - {mejor_modelo_nombre}:\")\n",
    "print(classification_report(y_test, resultados[mejor_modelo_nombre]['predicciones']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b44873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENTRENAMIENTO DE MODELOS ===\n",
      "‚úÖ SVM entrenado correctamente\n",
      "‚úÖ Decision Tree entrenado correctamente\n",
      "‚úÖ Random Forest entrenado correctamente\n",
      "‚úÖ XGBoost entrenado correctamente\n",
      "‚úÖ Naive Bayes entrenado correctamente\n",
      "‚úÖ KNN entrenado correctamente\n",
      "\n",
      "================================================================================\n",
      "COMPARACI√ìN DE M√âTRICAS POR MODELO\n",
      "================================================================================\n",
      "       Modelo  Accuracy  Precision  Recall  F1-Score\n",
      "          SVM    0.7320     0.7311  0.7320    0.7192\n",
      "Decision Tree    0.6315     0.6299  0.6315    0.6306\n",
      "Random Forest    0.7210     0.7089  0.7210    0.7103\n",
      "      XGBoost    0.7240     0.7144  0.7240    0.7169\n",
      "  Naive Bayes    0.6246     0.6443  0.6246    0.6276\n",
      "          KNN    0.6832     0.6696  0.6832    0.6728\n",
      "\n",
      "================================================================================\n",
      "üèÜ MEJOR MODELO SELECCIONADO\n",
      "================================================================================\n",
      "Modelo: SVM\n",
      "F1-Score: 0.7192\n",
      "Accuracy: 0.7320\n",
      "Precision: 0.7311\n",
      "Recall: 0.7320\n",
      "\n",
      "üìä REPORTE DETALLADO DEL MEJOR MODELO (SVM)\n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Nula       0.83      0.90      0.86      2342\n",
      "        Leve       0.57      0.52      0.54      1148\n",
      "    Moderada       0.63      0.64      0.64       772\n",
      "     Intensa       1.00      0.01      0.02       104\n",
      "\n",
      "    accuracy                           0.73      4366\n",
      "   macro avg       0.76      0.52      0.52      4366\n",
      "weighted avg       0.73      0.73      0.72      4366\n",
      "\n",
      "\n",
      "üìà DISTRIBUCI√ìN DE CLASES\n",
      "================================================================================\n",
      "          Real  Predicho\n",
      "Nula       NaN       NaN\n",
      "Leve       NaN       NaN\n",
      "Moderada   NaN       NaN\n",
      "Intensa    NaN       NaN\n",
      "\n",
      "üèÖ RANKING DE MODELOS (por F1-Score)\n",
      "================================================================================\n",
      " Posici√≥n        Modelo  F1-Score  Accuracy  Precision  Recall\n",
      "        1           SVM    0.7192    0.7320     0.7311  0.7320\n",
      "        2       XGBoost    0.7169    0.7240     0.7144  0.7240\n",
      "        3 Random Forest    0.7103    0.7210     0.7089  0.7210\n",
      "        4           KNN    0.6728    0.6832     0.6696  0.6832\n",
      "        5 Decision Tree    0.6306    0.6315     0.6299  0.6315\n",
      "        6   Naive Bayes    0.6276    0.6246     0.6443  0.6246\n",
      "\n",
      "üí° El mejor modelo 'SVM' est√° listo para hacer predicciones\n",
      "   Puedes usarlo como: mejor_modelo.predict(nuevos_datos)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargar datos\n",
    "#df = pd.read_csv('data.csv', parse_dates=['fecha'], dayfirst=True)\n",
    "df = pd.read_csv('dic1985-oct2025.csv', parse_dates=['fecha'])\n",
    "\n",
    "# Ingenier√≠a de caracter√≠sticas temporales\n",
    "df['dia_del_a√±o'] = df['fecha'].dt.dayofyear\n",
    "df['sin_dia'] = np.sin(2 * np.pi * df['dia_del_a√±o'] / 365.25)\n",
    "df['cos_dia'] = np.cos(2 * np.pi * df['dia_del_a√±o'] / 365.25)\n",
    "\n",
    "# Transformar a problema de clasificaci√≥n multiclase\n",
    "def clasificar_precipitacion(precip):\n",
    "    if precip == 0:\n",
    "        return 0  # Nula\n",
    "    elif precip <= 2:\n",
    "        return 1  # Leve\n",
    "    elif precip <= 15:\n",
    "        return 2  # Moderada\n",
    "    else:\n",
    "        return 3  # Intensa\n",
    "\n",
    "df['clase_precipitacion'] = df['precipitacion_total'].apply(clasificar_precipitacion)\n",
    "\n",
    "# Preparar caracter√≠sticas\n",
    "features = ['temp_max', 'temp_min', 'presion_max', 'presion_min', \n",
    "            'rocio_max', 'rocio_min', 'viento_promedio', 'radiacion', \n",
    "            'sin_dia', 'cos_dia']\n",
    "X = df[features]\n",
    "y = df['clase_precipitacion']\n",
    "\n",
    "# Escalado y divisi√≥n\n",
    "scaler = StandardScaler()\n",
    "X_escalado = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_escalado, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definir modelos\n",
    "modelos = {\n",
    "    'SVM': SVC(kernel='rbf', C=1.0, probability=True, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric='mlogloss'),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar modelos\n",
    "resultados = {}\n",
    "metricas_comparativas = []\n",
    "\n",
    "print(\"=== ENTRENAMIENTO DE MODELOS ===\")\n",
    "for nombre, modelo in modelos.items():\n",
    "    # Entrenamiento\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    y_pred_proba = modelo.predict_proba(X_test) if hasattr(modelo, \"predict_proba\") else None\n",
    "    \n",
    "    # Calcular m√©tricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Almacenar resultados\n",
    "    resultados[nombre] = {\n",
    "        'modelo': modelo,\n",
    "        'predicciones': y_pred,\n",
    "        'probabilidades': y_pred_proba,\n",
    "        'metricas': {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Guardar para comparaci√≥n\n",
    "    metricas_comparativas.append({\n",
    "        'Modelo': nombre,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úÖ {nombre} entrenado correctamente\")\n",
    "\n",
    "# Crear DataFrame comparativo\n",
    "df_comparativo = pd.DataFrame(metricas_comparativas)\n",
    "df_comparativo = df_comparativo.round(4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARACI√ìN DE M√âTRICAS POR MODELO\")\n",
    "print(\"=\"*80)\n",
    "print(df_comparativo.to_string(index=False))\n",
    "\n",
    "# Encontrar el mejor modelo basado en F1-Score\n",
    "mejor_modelo_info = df_comparativo.loc[df_comparativo['F1-Score'].idxmax()]\n",
    "mejor_modelo_nombre = mejor_modelo_info['Modelo']\n",
    "mejor_modelo = resultados[mejor_modelo_nombre]['modelo']\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üèÜ MEJOR MODELO SELECCIONADO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Modelo: {mejor_modelo_nombre}\")\n",
    "print(f\"F1-Score: {mejor_modelo_info['F1-Score']:.4f}\")\n",
    "print(f\"Accuracy: {mejor_modelo_info['Accuracy']:.4f}\")\n",
    "print(f\"Precision: {mejor_modelo_info['Precision']:.4f}\")\n",
    "print(f\"Recall: {mejor_modelo_info['Recall']:.4f}\")\n",
    "\n",
    "# Mostrar reporte detallado del mejor modelo\n",
    "print(f\"\\nüìä REPORTE DETALLADO DEL MEJOR MODELO ({mejor_modelo_nombre})\")\n",
    "print(\"=\"*80)\n",
    "y_pred_mejor = resultados[mejor_modelo_nombre]['predicciones']\n",
    "print(classification_report(y_test, y_pred_mejor, \n",
    "                          target_names=['Nula', 'Leve', 'Moderada', 'Intensa']))\n",
    "\n",
    "# Mostrar distribuci√≥n de clases real vs predicha\n",
    "print(\"\\nüìà DISTRIBUCI√ìN DE CLASES\")\n",
    "print(\"=\"*80)\n",
    "dist_real = y_test.value_counts().sort_index().values\n",
    "dist_pred = pd.Series(y_pred_mejor).value_counts().sort_index().values\n",
    "df_dist = pd.DataFrame({\n",
    "    'Real': dist_real,\n",
    "    'Predicho': dist_pred\n",
    "}, index=['Nula', 'Leve', 'Moderada', 'Intensa'])\n",
    "print(df_dist)\n",
    "\n",
    "# Ordenar modelos por F1-Score para ranking\n",
    "print(\"\\nüèÖ RANKING DE MODELOS (por F1-Score)\")\n",
    "print(\"=\"*80)\n",
    "df_ranking = df_comparativo.sort_values('F1-Score', ascending=False).reset_index(drop=True)\n",
    "df_ranking['Posici√≥n'] = df_ranking.index + 1\n",
    "df_ranking = df_ranking[['Posici√≥n', 'Modelo', 'F1-Score', 'Accuracy', 'Precision', 'Recall']]\n",
    "print(df_ranking.to_string(index=False))\n",
    "\n",
    "# El mejor modelo queda disponible para uso futuro\n",
    "print(f\"\\nüí° El mejor modelo '{mejor_modelo_nombre}' est√° listo para hacer predicciones\")\n",
    "print(\"   Puedes usarlo como: mejor_modelo.predict(nuevos_datos)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63e803c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pd.Series(y_pred_mejor)))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceab50fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2522\n",
      "1    1062\n",
      "2     781\n",
      "3       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(y_pred_mejor).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96c78082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clase_precipitacion\n",
      "0    2342\n",
      "1    1148\n",
      "2     772\n",
      "3     104\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37b6bcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà DISTRIBUCI√ìN DE CLASES\n",
      "================================================================================\n",
      "          Real  Predicho\n",
      "Nula      2342      2522\n",
      "Leve      1148      1062\n",
      "Moderada   772       781\n",
      "Intensa    104         1\n"
     ]
    }
   ],
   "source": [
    "# Mostrar distribuci√≥n de clases real vs predicha\n",
    "print(\"\\nüìà DISTRIBUCI√ìN DE CLASES\")\n",
    "print(\"=\"*80)\n",
    "dist_real = y_test.value_counts().sort_index().values\n",
    "dist_pred = pd.Series(y_pred_mejor).value_counts().sort_index().values\n",
    "df_dist = pd.DataFrame({\n",
    "    'Real': dist_real,\n",
    "    'Predicho': dist_pred\n",
    "}, index=['Nula', 'Leve', 'Moderada', 'Intensa'])\n",
    "print(df_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b8bd7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the classifier\n",
    "with open(f'{mejor_modelo_nombre}.pkl', 'wb') as fid:\n",
    "    pickle.dump(mejor_modelo, fid)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19c0d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
